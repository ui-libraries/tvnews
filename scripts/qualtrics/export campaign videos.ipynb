{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f136f45",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
      "\u001b[K     |████████████████████████████████| 239 kB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lxml>=3.1.0\n",
      "  Downloading lxml-5.2.1-cp39-cp39-macosx_10_9_universal2.whl (8.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.5 MB 26.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: typing-extensions, lxml, python-docx\n",
      "Successfully installed lxml-5.2.1 python-docx-1.1.0 typing-extensions-4.10.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install python-docx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aaa741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 123 unique videos to unique_videos.json.\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import json\n",
    "\n",
    "# Replace the following with your API key and playlist ID\n",
    "api_key = ''\n",
    "playlist_id = ''\n",
    "\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "def get_playlist_videos(playlist_id):\n",
    "    videos = []\n",
    "    video_ids_seen = set()  # To keep track of video IDs already seen\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        pl_request = youtube.playlistItems().list(\n",
    "            part='snippet',\n",
    "            playlistId=playlist_id,\n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token\n",
    "        )\n",
    "\n",
    "        pl_response = pl_request.execute()\n",
    "\n",
    "        for item in pl_response['items']:\n",
    "            video_id = item['snippet']['resourceId']['videoId']\n",
    "            title = item['snippet']['title']\n",
    "            url = f'https://www.youtube.com/watch?v={video_id}'\n",
    "\n",
    "            if video_id not in video_ids_seen:\n",
    "                video_ids_seen.add(video_id)\n",
    "                videos.append({\"title\": title, \"url\": url})\n",
    "        \n",
    "        next_page_token = pl_response.get('nextPageToken')\n",
    "\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return videos\n",
    "\n",
    "unique_videos = get_playlist_videos(playlist_id)\n",
    "\n",
    "# Saving the unique videos to a JSON file\n",
    "with open('unique_videos.json', 'w') as json_file:\n",
    "    json.dump(unique_videos, json_file, indent=4)\n",
    "\n",
    "print(f\"Exported {len(unique_videos)} unique videos to unique_videos.json.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "139dec5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated summaries have been added to unique_videos_updated.json.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from docx import Document\n",
    "\n",
    "# Replace this with the path to your 'ad_summaries' directory\n",
    "ad_summaries_dir = '/Users/mtbutler/Desktop/Campaign Qualtrics/ad_summaries'\n",
    "\n",
    "# Function to read the text from a Word document\n",
    "def read_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    fullText = []\n",
    "    for para in doc.paragraphs:\n",
    "        fullText.append(para.text)\n",
    "    return '\\n'.join(fullText)\n",
    "\n",
    "# Load the existing JSON data\n",
    "with open('unique_videos.json', 'r') as json_file:\n",
    "    videos = json.load(json_file)\n",
    "\n",
    "# Function to adjust the directory name based on the title\n",
    "def adjust_dir_name(title):\n",
    "    # Replace spaces with hyphens and remove 'wm' suffix if present\n",
    "    adjusted_title = title.replace(\" \", \"-\")\n",
    "    if adjusted_title.endswith(\"-wm\"):\n",
    "        adjusted_title = adjusted_title[:-3]  # Remove the last 3 characters (\"-wm\")\n",
    "    return adjusted_title\n",
    "\n",
    "# Iterate through each video in the JSON file\n",
    "for video in videos:\n",
    "    title = video[\"title\"]\n",
    "    # Adjust the directory name based on the title\n",
    "    dir_name = adjust_dir_name(title)\n",
    "    full_dir_path = os.path.join(ad_summaries_dir, dir_name)\n",
    "    \n",
    "    # Initialize summaries in video object\n",
    "    video['summary_1'] = ''\n",
    "    video['summary_2'] = ''\n",
    "    video['summary_3'] = ''\n",
    "\n",
    "    # Check if the directory exists\n",
    "    if os.path.exists(full_dir_path):\n",
    "        # Iterate through each summary file and update the video object\n",
    "        for summary_name in ['summary_1.docx', 'summary_2.docx', 'summary_3.docx']:\n",
    "            summary_path = os.path.join(full_dir_path, summary_name)\n",
    "            if os.path.isfile(summary_path):\n",
    "                video[summary_name.split('.')[0]] = read_docx(summary_path)\n",
    "\n",
    "# Write the updated data back to the JSON file\n",
    "with open('unique_videos_updated.json', 'w') as json_file:\n",
    "    json.dump(videos, json_file, indent=4)\n",
    "\n",
    "print(\"Updated summaries have been added to unique_videos_updated.json.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ff45ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Data saved to 'unique_videos_processed.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Step 1: Read the JSON data from unique_videos_updated.json\n",
    "with open('unique_videos_updated.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "updated_data = []\n",
    "\n",
    "for item in data:\n",
    "    # Filter summaries to include only non-empty ones and pair them with their number (1, 2, or 3)\n",
    "    summaries = [(key[-1], value) for key, value in item.items() if key.startswith('summary') and value]\n",
    "    # Randomly select two summaries, duplicate if necessary\n",
    "    selected_summaries = random.sample(summaries, 2) if len(summaries) > 1 else summaries * 2\n",
    "\n",
    "    # Construct the new object format\n",
    "    new_item = {\n",
    "        \"title\": item[\"title\"],\n",
    "        \"url\": item[\"url\"],\n",
    "        \"A\": selected_summaries[0][1],\n",
    "        \"B\": selected_summaries[1][1],\n",
    "        \"selection\": [int(selected_summaries[0][0]), int(selected_summaries[1][0])]\n",
    "    }\n",
    "    updated_data.append(new_item)\n",
    "\n",
    "# Step 3: (Optional) Write the processed data back to a new JSON file\n",
    "with open('unique_videos_processed.json', 'w') as outfile:\n",
    "    json.dump(updated_data, outfile, indent=4)\n",
    "\n",
    "print(\"Processing complete. Data saved to 'unique_videos_processed.json'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8902bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "# Path to your JSON file - update this to the location of your JSON file\n",
    "json_file_path = 'unique_videos_processed.json'\n",
    "\n",
    "# Path to where you want the CSV file to be saved - update this as needed\n",
    "csv_file_path = 'videos_for_qualtrics.csv'\n",
    "\n",
    "# Function to safely encode text for CSV\n",
    "def encode_for_csv(text):\n",
    "    if isinstance(text, list):  # Convert list to string if necessary\n",
    "        return ';'.join(str(num) for num in text)\n",
    "    return text.replace('\"', '\"\"')  # Escape double quotes by doubling them\n",
    "\n",
    "# Read the JSON data\n",
    "with open(json_file_path, 'r', encoding='utf-8') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "# Write the JSON data to a CSV file\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file, quoting=csv.QUOTE_ALL)  # Use QUOTE_ALL to handle commas and quotes in text\n",
    "    # Write the header row\n",
    "    writer.writerow(['Title', 'URL', 'Summary_A', 'Summary_B', 'Selection'])\n",
    "\n",
    "    for video in json_data:\n",
    "        writer.writerow([\n",
    "            encode_for_csv(video.get('title', '')),\n",
    "            encode_for_csv(video.get('url', '')),\n",
    "            encode_for_csv(video.get('A', '')),\n",
    "            encode_for_csv(video.get('B', '')),\n",
    "            encode_for_csv(video.get('selection', ''))\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e346225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
